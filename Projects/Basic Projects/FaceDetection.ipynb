{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ae8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2c4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image1.jfif\", 1)\n",
    "\n",
    "# im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) --------------------------> default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a1b1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "imshow() is used to show the read image and takes two parameters: 1. window-name and 2. image to be returned\n",
    "\"\"\"\n",
    "cv2.imshow('Image',img)\n",
    "\n",
    "\"\"\"\n",
    "cv2.waitKey() specifies the total time duration of the display.\n",
    "If passed 0, it will showcase the output till any key is hit. It takes parameters as time in milliseconds.\n",
    "The function is very important as it avoids the Python kernel from crashing.\n",
    "\"\"\"\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\"\"\"\n",
    "closes all the open windows.\n",
    "\"\"\"\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640812d3",
   "metadata": {},
   "source": [
    "#### For GrayScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b913171",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image1.jfif\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2d3ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef302e",
   "metadata": {},
   "source": [
    "#### Picture Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "423cfb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.resize(img, (700,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "124f35a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('Image',img)\n",
    "# # cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24cae76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-13f6cce48c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.resize(img, (0,0), fx=0.3, fy=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "168204c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d571a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[242 220 184]\n",
      "  [243 221 184]\n",
      "  [242 223 183]\n",
      "  ...\n",
      "  [237 216 179]\n",
      "  [237 215 178]\n",
      "  [237 215 177]]\n",
      "\n",
      " [[243 221 185]\n",
      "  [243 223 185]\n",
      "  [242 223 185]\n",
      "  ...\n",
      "  [238 217 179]\n",
      "  [238 217 179]\n",
      "  [238 217 179]]\n",
      "\n",
      " [[242 222 187]\n",
      "  [242 223 185]\n",
      "  [242 223 185]\n",
      "  ...\n",
      "  [237 218 179]\n",
      "  [237 217 179]\n",
      "  [238 217 179]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[154 122  99]\n",
      "  [153 123  97]\n",
      "  [153 124  97]\n",
      "  ...\n",
      "  [143 112  89]\n",
      "  [143 112  88]\n",
      "  [142 111  88]]\n",
      "\n",
      " [[154 122  99]\n",
      "  [153 123  97]\n",
      "  [152 123  97]\n",
      "  ...\n",
      "  [142 111  88]\n",
      "  [142 111  89]\n",
      "  [141 110  88]]\n",
      "\n",
      " [[153 120  99]\n",
      "  [152 121  96]\n",
      "  [151 121  96]\n",
      "  ...\n",
      "  [141 109  88]\n",
      "  [141 110  87]\n",
      "  [141 110  88]]]\n",
      "(150, 210, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "the third argument is related to grayscale since I gave colored image thats why it should(150,10,3)\n",
    "\"\"\"\n",
    "print(img)\n",
    "print(img.shape) #returns shape of numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f64b4",
   "metadata": {},
   "source": [
    "# Detect Eyes and Detect Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06ad827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae3bc864",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = sys.argv[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0236a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'image1.jfif'\n",
    "cascPath = \"haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "821624ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +  \"haarcascade_eye.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0e607ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad3ac29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faceCascade = cv2.CascadeClassifier(cascPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e135f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "image = cv2.imread(imagePath)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d493da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect faces in the image\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30),\n",
    "    flags = cv2.CASCADE_SCALE_IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8da2bba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 faces!\n"
     ]
    }
   ],
   "source": [
    "print (\"Found {0} faces!\".format(len(faces)))\n",
    "\n",
    "# Draw a rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec9fc624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Faces found\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021ef28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
