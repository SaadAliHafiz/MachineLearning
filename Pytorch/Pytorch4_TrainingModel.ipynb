{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84461552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383293f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7a2e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "net=Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83a15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73cf28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.view(-1,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a74396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3081, -2.3440, -2.3459, -2.1404, -2.2314, -2.2845, -2.4134, -2.2376,\n",
       "         -2.3605, -2.3920]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06deb17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f662d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ecc2913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1b30c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.971\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))\n",
    "Accuracy:  0.968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76b9834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d79bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.6764e+01, -1.3225e+01, -1.1208e+01, -1.3470e+01, -2.1072e+01,\n",
      "        -1.8410e+01, -4.1940e+01, -1.7881e-05, -1.8659e+01, -1.3762e+01],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a_featureset = X[0]\n",
    "reshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\n",
    "output = net(reshaped_for_network) #output will be a list of network predictions.\n",
    "first_pred = output[0]\n",
    "print(first_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcfaaba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "biggest_index = torch.argmax(first_pred)\n",
    "print(biggest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071fbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
